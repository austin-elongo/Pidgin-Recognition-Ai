{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook serves to align the word vectors of West African Pidgin (Creole) and English Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from utils import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getknn(sc, x, y, k=10):\n",
    "    sidx = np.argpartition(sc, -k, axis=1)[:, -k:]\n",
    "    ytopk = y[sidx.flatten(), :]\n",
    "    ytopk = ytopk.reshape(sidx.shape[0], sidx.shape[1], y.shape[1])\n",
    "    f = np.sum(sc[np.arange(sc.shape[0])[:, None], sidx])\n",
    "    df = np.dot(ytopk.sum(1).T, x)\n",
    "    return f / k, df / k\n",
    "\n",
    "\n",
    "def rcsls(X_src, Y_tgt, Z_src, Z_tgt, R, knn=10):\n",
    "    X_trans = np.dot(X_src, R.T)\n",
    "    f = 2 * np.sum(X_trans * Y_tgt)\n",
    "    df = 2 * np.dot(Y_tgt.T, X_src)\n",
    "    fk0, dfk0 = getknn(np.dot(X_trans, Z_tgt.T), X_src, Z_tgt, knn)\n",
    "    fk1, dfk1 = getknn(np.dot(np.dot(Z_src, R.T), Y_tgt.T).T, Y_tgt, Z_src, knn)\n",
    "    f = f - fk0 -fk1\n",
    "    df = df - dfk0 - dfk1.T\n",
    "    return -f / X_src.shape[0], -df / X_src.shape[0]\n",
    "\n",
    "\n",
    "def proj_spectral(R):\n",
    "    U, s, V = np.linalg.svd(R)\n",
    "    s[s > 1] = 1\n",
    "    s[s < 0] = 0\n",
    "    return np.dot(U, np.dot(np.diag(s), V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Specify Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='RCSLS for supervised word alignment')\n",
    "\n",
    "parser.add_argument(\"--src_emb\", type=str, default='', help=\"Load source embeddings\")\n",
    "parser.add_argument(\"--tgt_emb\", type=str, default='', help=\"Load target embeddings\")\n",
    "parser.add_argument('--center', action='store_true', help='whether to center embeddings or not')\n",
    "\n",
    "parser.add_argument(\"--dico_train\", type=str, default='', help=\"train dictionary\")\n",
    "parser.add_argument(\"--dico_test\", type=str, default='', help=\"validation dictionary\")\n",
    "\n",
    "parser.add_argument(\"--output\", type=str, default='', help=\"where to save aligned embeddings\")\n",
    "\n",
    "parser.add_argument(\"--knn\", type=int, default=10, help=\"number of nearest neighbors in RCSL/CSLS\")\n",
    "parser.add_argument(\"--maxneg\", type=int, default=200000, help=\"Maximum number of negatives for the Extended RCSLS\")\n",
    "parser.add_argument(\"--maxsup\", type=int, default=-1, help=\"Maximum number of training examples\")\n",
    "parser.add_argument(\"--maxload\", type=int, default=200000, help=\"Maximum number of loaded vectors\")\n",
    "\n",
    "parser.add_argument(\"--model\", type=str, default=\"none\", help=\"Set of constraints: spectral or none\")\n",
    "parser.add_argument(\"--reg\", type=float, default=0.0 , help='regularization parameters')\n",
    "\n",
    "parser.add_argument(\"--lr\", type=float, default=1.0, help='learning rate')\n",
    "parser.add_argument(\"--niter\", type=int, default=10, help='number of iterations')\n",
    "parser.add_argument('--sgd', action='store_true', help='use sgd')\n",
    "parser.add_argument(\"--batchsize\", type=int, default=32, help=\"batch size for sgd\")\n",
    "parser.add_argument(\"--no_words_src\", type = int, default = 413412, help = \"number of source words\")\n",
    "parser.add_argument(\"--no_words_tgt\", type = int, default = 400000, help = \"number of target words\")\n",
    "parser.add_argument(\"--src_txt_format\", type = str, default = \"w2v\", help = \"Format of text file containing source embeddings\")\n",
    "parser.add_argument(\"--tgt_txt_format\", type = str, default = \"glove\", help = \"Format of text file containing target embeddings\")\n",
    "parser.add_argument(\"--dim\", type = int, default = 300, help = \"Dimension of embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, unknown = parser.parse_known_args() #parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify arguments\n",
    "\n",
    "params.src_emb = 'cbow_15.txt'\n",
    "params.tgt_emb = 'glove.6B.300d.txt'\n",
    "params.maxload = 500000\n",
    "params.dico_train = 'final_dict.txt'\n",
    "params.dico_test = 'eval_dict.txt'\n",
    "params.output = 'pidg_vect.txt'\n",
    "params.matrix = 'matrix.txt'\n",
    "params.niter = 15\n",
    "params.lr = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word embeddings\n",
    "words_tgt, x_tgt = load_vectors(params.tgt_emb, params, False, center=params.center)\n",
    "words_src, x_src = load_vectors(params.src_emb, params, True, center=params.center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation bilingual lexicon\n",
    "src2tgt, lexicon_size = load_lexicon(params.dico_test, words_src, words_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word --> vector indices\n",
    "idx_src = idx(words_src)\n",
    "idx_tgt = idx(words_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train bilingual lexicon\n",
    "pairs = load_pairs(params.dico_train, idx_src, idx_tgt)\n",
    "if params.maxsup > 0 and params.maxsup < len(pairs):\n",
    "    pairs = pairs[:params.maxsup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting training vector  pairs\n",
    "X_src, Y_tgt = select_vectors_from_pairs(x_src, x_tgt, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding negatives for RCSLS\n",
    "Z_src = x_src[:params.maxneg, :]\n",
    "Z_tgt = x_tgt[:params.maxneg, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization:\n",
    "R = procrustes(X_src, Y_tgt)\n",
    "nnacc = compute_nn_accuracy(np.dot(x_src, R.T), x_tgt, src2tgt, lexicon_size=lexicon_size)\n",
    "print(\"[init -- Procrustes] NN: %.4f\"%(nnacc))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "fold, Rold = 0, []\n",
    "niter, lr = params.niter, params.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(0, niter + 1):\n",
    "    if lr < 1e-4:\n",
    "        break\n",
    "\n",
    "    if params.sgd:\n",
    "        indices = np.random.choice(X_src.shape[0], size=params.batchsize, replace=False)\n",
    "        f, df = rcsls(X_src[indices, :], Y_tgt[indices, :], Z_src, Z_tgt, R, params.knn)\n",
    "    else:\n",
    "        f, df = rcsls(X_src, Y_tgt, Z_src, Z_tgt, R, params.knn)\n",
    "\n",
    "    if params.reg > 0:\n",
    "        R *= (1 - lr * params.reg)\n",
    "    R -= lr * df\n",
    "    if params.model == \"spectral\":\n",
    "        R = proj_spectral(R)\n",
    "\n",
    "    print(\"[it=%d] f = %.4f\" % (it, f))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if f > fold and it > 0 and not params.sgd:\n",
    "        lr /= 2\n",
    "        f, R = fold, Rold\n",
    "\n",
    "    fold, Rold = f, R\n",
    "\n",
    "    if (it > 0 and it % 10 == 0) or it == niter:\n",
    "        nnacc = compute_nn_accuracy(np.dot(x_src, R.T), x_tgt, src2tgt, lexicon_size=lexicon_size)\n",
    "        print(\"[it=%d] NN = %.4f - Coverage = %.4f\" % (it, nnacc, len(src2tgt) / lexicon_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnacc = compute_nn_accuracy(np.dot(x_src, R.T), x_tgt, src2tgt, lexicon_size=lexicon_size)\n",
    "print(\"[final] NN = %.4f - Coverage = %.4f\" % (nnacc, len(src2tgt) / lexicon_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Aligned Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.output != \"\":\n",
    "    print(\"Saving all aligned vectors at %s\" % params.output)\n",
    "    #load_vectors(params.src_emb, maxload=-1, center=params.center, verbose=False)\n",
    "    words_full, x_full = load_vectors(params.src_emb, params.no_words_src, params, True, maxload=params.maxload, center=params.center, verbose = False)\n",
    "    x = np.dot(x_full, R.T)\n",
    "    x /= np.linalg.norm(x, axis=1)[:, np.newaxis] + 1e-8\n",
    "    save_vectors(params.output, x, words_full)\n",
    "    save_matrix(params.matrix,  R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
