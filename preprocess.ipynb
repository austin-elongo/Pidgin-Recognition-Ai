{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook preprocesses the all text datasets - monolingual corpus and parallel data - and saves then in a serialized form to be loaded for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('punkt')",
    "\n",
    "from src.logger import create_logger\n",
    "from src.data.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(voc_path:str, txt_path:str, bin_path:str, glove = False):\n",
    "    \n",
    "    '''\n",
    "    voc_path: path to word vectors\n",
    "    txt_path: path to corpus or parallel data text file\n",
    "    bin_path: path to serialized data. If such a file exists in the path, the data is loaded from there, if not, \n",
    "    a file is created and the data stored there.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    logger = create_logger(None)\n",
    "\n",
    "    voc_path = voc_path\n",
    "    txt_path = txt_path\n",
    "    bin_path = bin_path\n",
    "    assert os.path.isfile(voc_path)\n",
    "    assert os.path.isfile(txt_path)\n",
    "\n",
    "    dico = Dictionary.read_vocab(voc_path, glove)\n",
    "    logger.info(\"\")\n",
    "\n",
    "    data = Dictionary.index_data(txt_path, bin_path, dico)\n",
    "    logger.info(\"%i words (%i unique) in %i sentences.\" % (\n",
    "        len(data['sentences']) - len(data['positions']),\n",
    "        len(data['dico']),\n",
    "        len(data['positions'])\n",
    "    ))\n",
    "    if len(data['unk_words']) > 0:\n",
    "        logger.info(\"%i unknown words (%i unique), covering %.2f%% of the data.\" % (\n",
    "            sum(data['unk_words'].values()),\n",
    "            len(data['unk_words']),\n",
    "            sum(data['unk_words'].values()) * 100. / (len(data['sentences']) - len(data['positions']))\n",
    "        ))\n",
    "        if len(data['unk_words']) < 30:\n",
    "            for w, c in sorted(data['unk_words'].items(), key=lambda x: x[1])[::-1]:\n",
    "                logger.info(\"%s: %i\" % (w, c))\n",
    "    else:\n",
    "        logger.info(\"0 unknown word.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = zip(['en_train', 'en_valid', 'en_test', 'en_para_valid','en_para_test'], ('en_train.txt', 'en_valid.txt', 'en_test.txt'\\\n",
    "                                                                                'en_para_valid.txt','en_para_test.txt'\n",
    "                                                                              ))\n",
    "pd = zip(['pd_train', 'pd_valid', 'pd_test','pd_para_valid','pd_para_test' ], ('pd_train.txt', 'pd_valid.txt','pd_test.txt',\\\n",
    "                                                                               'pd_para_valid.txt','pd_para_test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in en:\n",
    "    preprocess('pidg_vect_RCSLS.txt', path, name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in pd:\n",
    "    preprocess('pidg_vect_RCSLS.txt', path, name+'.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
